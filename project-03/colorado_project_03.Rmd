---
title: "Data Visualization for Exploratory Data Analysis"
output: 
  html_document:
    keep_md: true
    toc: true
    toc_float: true
---

# Data Visualization Project 03

In this exercise you will explore methods to create different types of data visualizations (such as plotting text data, or exploring the distributions of continuous variables).

## PART 1: Density Plots

Using the dataset obtained from FSU's [Florida Climate Center](https://climatecenter.fsu.edu/climate-data-access-tools/downloadable-data), for a station at Tampa International Airport (TPA) for 2022, attempt to recreate the charts shown below which were generated using data from 2016. You can read the 2022 dataset using the code below:

```{r}
library(ggridges)
library(tidyverse)
library(viridis)
```

```{r, message=FALSE, warning=FALSE}

weather_tpa <- read_csv("https://raw.githubusercontent.com/reisanar/datasets/master/tpa_weather_2022.csv")
# random sample 
sample_n(weather_tpa, 4)
```

See <https://www.reisanar.com/slides/relationships-models#10> for a reminder on how to use this type of dataset with the `lubridate` package for dates and times (example included in the slides uses data from 2016).

Using the 2022 data:

(a) Create a plot like the one below:

```{r, echo = FALSE, out.width="80%", fig.align='center'}
knitr::include_graphics("https://github.com/reisanar/figs/raw/master/tpa_max_temps_facet.png")
```

Hint: the option `binwidth = 3` was used with the `geom_histogram()` function.

```{r}
library(lubridate)
weather_tpa$month <- month(weather_tpa$month, label = T, abbr = F)
```

```{r}
weather_tpa
```

```{r}
temp_histogram <- ggplot(data=weather_tpa)+
  geom_histogram(aes(x=max_temp, fill=month),binwidth =3,,col=I("white"), show.legend = FALSE)+
  facet_wrap(~ month, nrow = 3, ncol = 4)+
  theme(legend.position="none")+
  scale_y_continuous(limits = c(0, 20))+
  scale_x_continuous(limits = c(60, 90))+
  ylab("Number of Days")+
  xlab("Maximum Temperature")+
  theme_bw()
```

```{r}
#ggsave("temp_histogram.jpg", plot = temp_histogram, dpi = 300)
```

(b) Create a plot like the one below:

```{r, echo = FALSE, out.width="80%", fig.align='center'}
knitr::include_graphics("https://github.com/reisanar/figs/raw/master/tpa_max_temps_density.png")
```

Hint: check the `kernel` parameter of the `geom_density()` function, and use `bw = 0.5`.

```{r}
density_plot<-ggplot(data=weather_tpa,aes(x=max_temp))+
  geom_density(bw = 0.5,kernel = "epanechnikov",color="black",fill="#7c7c7c")+
  theme(legend.position="none")+
  scale_x_continuous(limits = c(60, 90))+
  ylab("Number of Days")+
  xlab("Maximum Temperature")+
  theme_minimal()
```

```{r}
#ggsave("density_plot.jpg", plot = density_plot, dpi = 300)

```

For this one to make sure I got the correct shade of grey I used this ![color matching website](https://designs.ai/colors) after taking screenshot of the provided image it gave me the hex code values of the color

(c) Create a plot like the one below:

```{r, echo = FALSE, out.width="80%", fig.align='center'}
knitr::include_graphics("https://github.com/reisanar/figs/raw/master/tpa_max_temps_density_facet.png")
```

Hint: default options for `geom_density()` were used.

```{r warning=FALSE}
density_plot2022<-ggplot(data=weather_tpa,aes(x=max_temp,fill=month,col=I("black")))+
  geom_density(bw = 1,kernel = "epanechnikov", nrow =3, ncol = 4, alpha=.8)+
  facet_wrap(~ month)+  
  labs(x = "Maximum temperatures", y = " ", title = "Density plot for each month in 2022")+
  scale_x_continuous(limits = c(60, 90))+
  theme_bw()+
  theme(legend.position="none")
```

```{r}
#ggsave("density_plot2022.jpg", plot = density_plot2022, dpi = 300)

```

(d) Generate a plot like the chart below:

```{r, echo = FALSE, out.width="80%", fig.align='center'}
knitr::include_graphics("https://github.com/reisanar/figs/raw/master/tpa_max_temps_ridges_plasma.png")
```

Hint: use the`{ggridges}` package, and the `geom_density_ridges()` function paying close attention to the `quantile_lines` and `quantiles` parameters. The plot above uses the `plasma` option (color scale) for the *viridis* palette.

```{r}
ridges <-ggplot(weather_tpa, aes(x = max_temp, y = month, fill = stat(x))) +
  geom_density_ridges_gradient(quantile_lines = TRUE, quantiles = c(0.5)) +
  scale_fill_viridis_c(name = "", option = "C") +
  theme_minimal()+
  labs(x = "Maximum temperature (in Fahrenheit degrees)",
       y = "")+
  theme_minimal()
```

```{r}
#ggsave("ridges.jpg", plot = ridges, dpi = 300)

```


(e) Create a plot of your choice that uses the attribute for precipitation *(values of -99.9 for temperature or -99.99 for precipitation represent missing data)*.

```{r}
weather_tpa <- weather_tpa %>%
  group_by(month) %>%
  mutate(
    avg_precipitation = mean(precipitation)
  ) 
```

```{r}
avg_precipitation<-ggplot(data=weather_tpa, mapping = aes( x=month,y=avg_precipitation,fill=month)) +
   geom_pointrange(aes(ymin=0, ymax=avg_precipitation),show.legend =FALSE)+
  labs(y = "precipitation", title="Average Precipitation in 2022")+
  coord_flip()+
  theme_classic()
```

```{r}
#ggsave("avg_precipitation.jpg", plot = avg_precipitation, dpi = 300)

```

## PART 2

### Option (A): Visualizing Text Data

Review the set of slides (and additional resources linked in it) for visualizing text data: <https://www.reisanar.com/slides/text-viz#1>

Choose any dataset with text data, and create at least one visualization with it. For example, you can create a frequency count of most used bigrams, a sentiment analysis of the text data, a network visualization of terms commonly used together, and/or a visualization of a topic modeling approach to the problem of identifying words/documents associated to different topics in the text data you decide to use.

Make sure to include a copy of the dataset in the `data/` folder, and reference your sources if different from the ones listed below:

-   [Billboard Top 100 Lyrics](https://github.com/reisanar/datasets/blob/master/BB_top100_2015.csv)

-   [RateMyProfessors comments](https://github.com/reisanar/datasets/blob/master/rmp_wit_comments.csv)

-   [FL Poly News Articles](https://github.com/reisanar/datasets/blob/master/flpoly_news_SP23.csv)

(to get the "raw" data from any of the links listed above, simply click on the `raw` button of the GitHub page and copy the URL to be able to read it in your computer using the `read_csv()` function)

```{r}
billboard<-read_csv("https://raw.githubusercontent.com/reisanar/datasets/master/BB_top100_2015.csv")
```
```{r}
write.csv(billboard, "../data/billboard.csv", row.names = FALSE)
```



```{r}
billboard
```

For this visualization I want to make a word map using the lyrics to see which words are used the most in popular songs

```{r}
library(wordcloud)
library(geniusr)
library(tidytext)
```

```{r}
billboard<-billboard %>% 
  unnest_tokens(word, Lyrics)
```

```{r}
billboard %>% 
  count(word, sort = TRUE)
```

```{r}
billboard<-billboard %>% 
  anti_join(stop_words)

```

```{r}
billboard <- billboard %>% 
  count(word, sort = TRUE)
```

```{r}

library(wordcloud2)
set.seed(1031)
wordcloud2(data=billboard)
```
